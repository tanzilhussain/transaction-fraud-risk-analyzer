```markdown
# ğŸ’³ Transaction Risk Analyzer

**Transaction Risk Analyzer** is a fully interactive Streamlit dashboard that explains how an XGBoost classification model detects potentially fraudulent financial transactions. By leveraging SHAP (SHapley Additive exPlanations), the app translates complex model behavior into intuitive visualizations, making it easier to understand AI-driven fraud detection systems.

---

## ğŸ¯ Purpose

This tool bridges technical transparency with user accessibility. Whether you're an ML practitioner, analyst, or someone curious about responsible AI, this project helps you:

- Understand the reasoning behind fraud predictions at both local (per-transaction) and global (model-wide) levels
- Interpret how specific features (amounts, balances, transaction types) influence model output
- Visualize SHAP explanations to demystify the "black box" nature of tree-based models

---

## ğŸ§  Technical Features

- âš™ï¸ **XGBoost Binary Classifier** trained on structured transactional data
- ğŸ’¡ **SHAP Value Generation** using `shap.Explainer` and `shap.Explanation` objects
- ğŸ“ˆ **Model-Wide Explanation** with SHAP summary bar plots
- ğŸ§  **Per-Transaction Explanations** with ranked SHAP values and natural language insights
- ğŸ§ª **Streamlit Frontend** for real-time user interaction
- ğŸ§µ Modular architecture supporting precomputed SHAP values and stored model objects (`.pkl`)

---
<pre> ``` â”œâ”€â”€ app.py # Streamlit app for SHAP-based fraud explanation â”œâ”€â”€ style.css # Optional custom styling for Streamlit â”œâ”€â”€ sample_transactions.csv # Subset of labeled sample transactions â”œâ”€â”€ transactions.csv # Full dataset of financial transactions â”œâ”€â”€ shap_input.csv # Precomputed SHAP values â”œâ”€â”€ shap_explanations.csv # Additional SHAP breakdowns (optional) â”œâ”€â”€ xgb_model.json # Saved XGBoost model structure â”œâ”€â”€ label_encoder.pkl # Encoder for categorical transaction types â”œâ”€â”€ README.md # Project overview and instructions â”œâ”€â”€ LICENSE # MIT License â”œâ”€â”€ .gitignore # Git ignored files â”‚ â”œâ”€â”€ explore_data.ipynb # Notebook for data exploration â”œâ”€â”€ model_training.ipynb # Notebook for model development â”œâ”€â”€ model_explainer.ipynb # Notebook for SHAP explanation generation â”œâ”€â”€ selecting_transactions.ipynb # Logic for selecting and saving demo samples â”‚ â”œâ”€â”€ archive/ # Folder for archived files â”œâ”€â”€ eda/ # Folder for EDA-related scripts/notebooks â””â”€â”€ venv/ # Python virtual environment ``` </pre>

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/transaction-risk-analyzer.git
cd transaction-risk-analyzer
````

### 2. Set Up Environment

```bash
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt
```

### 3. Launch the App

```bash
streamlit run app.py
```

---

## ğŸ“Œ SHAP Setup (Optional)

If you're not using the precomputed `shap_input.csv`, you can dynamically generate SHAP values with:

```python
from shap import Explainer
import joblib

model = joblib.load("xgb_fraud_model.pkl")
explainer = Explainer(model)
shap_values = explainer(X_all)
```

---

## âš–ï¸ Model Info

* **Model**: XGBoost Classifier (`xgb.XGBClassifier`)
* **Metrics**: Tuned for precision-recall tradeoffs on imbalanced datasets
* **Features Used**:

  * `amount`, `step`, `oldbalanceOrg`, `newbalanceOrig`
  * `oldbalanceDest`, `newbalanceDest`, `encoded_type`

---

## ğŸ§  Why SHAP?

SHAP provides model-agnostic explanations grounded in cooperative game theory. It breaks down the contribution of each feature to the prediction, making the decision process interpretable and auditable.

---

## ğŸ‘¤ Author

Made with â¤ï¸ by [Tanzil Hussain](https://www.linkedin.com/in/tanzilhussain)
Connect with me to chat about AI, responsible ML, and data-driven UX.

---

## ğŸ“„ License

MIT License â€” use with purpose and responsibility.

```
